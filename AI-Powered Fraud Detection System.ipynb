{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler, LabelEncoder\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import warnings\n",
        "import os\n",
        "\n",
        "# Professional Setup\n",
        "warnings.filterwarnings('ignore')\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"üöÄ Starting Hybrid AI Fraud Detection System...\")\n",
        "\n",
        "# ==========================================\n",
        "# 1. LOAD & ENGINEER DATA\n",
        "# ==========================================\n",
        "print(\"Step 1: Loading & Engineering Data...\")\n",
        "\n",
        "def engineer_features(df):\n",
        "    data = df.copy()\n",
        "\n",
        "    # Ensure timestamp exists\n",
        "    if 'timestamp' not in data.columns:\n",
        "        # Create dummy timestamps if missing to prevent crash\n",
        "        data['timestamp'] = pd.date_range('2024-01-01', periods=len(data), freq='T')\n",
        "    else:\n",
        "        data['timestamp'] = pd.to_datetime(data['timestamp'])\n",
        "\n",
        "    data = data.sort_values(['customer_id', 'timestamp'])\n",
        "\n",
        "    # 1. Velocity (Behavioral)\n",
        "    data['prev_time'] = data.groupby('customer_id')['timestamp'].shift(1)\n",
        "    data['seconds_diff'] = (data['timestamp'] - data['prev_time']).dt.total_seconds().fillna(0)\n",
        "\n",
        "    # 2. Z-Score (Statistical)\n",
        "    cust_stats = data.groupby('customer_id')['amount'].agg(['mean', 'std']).reset_index()\n",
        "    data = data.merge(cust_stats, on='customer_id', how='left')\n",
        "    data['std'] = data['std'].fillna(1)\n",
        "    data['z_score'] = (data['amount'] - data['mean']) / (data['std'] + 1e-5)\n",
        "\n",
        "    # 3. Time & Category\n",
        "    data['hour'] = data['timestamp'].dt.hour\n",
        "    data['merchant_category'] = data['merchant_category'].astype(str)\n",
        "\n",
        "    # 4. Encoding\n",
        "    le = LabelEncoder()\n",
        "    data['cat_code'] = le.fit_transform(data['merchant_category'])\n",
        "\n",
        "    return data\n",
        "\n",
        "# Load Training Data\n",
        "try:\n",
        "    if os.path.exists(\"fraud_dataset.csv\"):\n",
        "        df_raw = pd.read_csv(\"fraud_dataset.csv\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è 'fraud_dataset.csv' not found. Generating SYNTHETIC training data...\")\n",
        "        df_raw = pd.DataFrame({\n",
        "            'transaction_id': range(5000),\n",
        "            'customer_id': np.random.randint(1000, 1100, 5000),\n",
        "            'amount': np.random.exponential(50, 5000),\n",
        "            'merchant_category': np.random.choice(['food','travel','tech'], 5000),\n",
        "            'is_fraud': 0\n",
        "        })\n",
        "        df_raw.loc[0:100, 'is_fraud'] = 1 # Inject fraud\n",
        "\n",
        "    df_proc = engineer_features(df_raw)\n",
        "    FEATURES = ['amount', 'seconds_diff', 'z_score', 'hour', 'cat_code']\n",
        "    X = df_proc[FEATURES]\n",
        "    y = df_proc['is_fraud']\n",
        "\n",
        "    # Scale Data (Crucial for Neural Networks)\n",
        "    scaler = MinMaxScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "    # ==========================================\n",
        "    # 2. TRAIN HYBRID SYSTEM\n",
        "    # ==========================================\n",
        "    print(\"Step 2: Training Hybrid Engines...\")\n",
        "\n",
        "    # A. Autoencoder (Unsupervised Anomaly Detection)\n",
        "    # Train ONLY on Normal transactions to learn \"Normality\"\n",
        "    X_normal = X_scaled[y == 0]\n",
        "    autoencoder = MLPRegressor(hidden_layer_sizes=(16, 8, 16), random_state=42, max_iter=200)\n",
        "    autoencoder.fit(X_normal, X_normal)\n",
        "    print(\"   ‚úÖ Autoencoder Trained (Anomaly Engine)\")\n",
        "\n",
        "    # B. XGBoost (Supervised Pattern Recognition)\n",
        "    # Use SMOTE to fix Class Imbalance\n",
        "    smote = SMOTE(random_state=42)\n",
        "    X_res, y_res = smote.fit_resample(X_scaled, y)\n",
        "\n",
        "    xgb_model = xgb.XGBClassifier(n_estimators=100, max_depth=4, use_label_encoder=False, eval_metric='logloss')\n",
        "    xgb_model.fit(X_res, y_res)\n",
        "    print(\"   ‚úÖ XGBoost Trained with SMOTE (Pattern Engine)\")\n",
        "\n",
        "    # ==========================================\n",
        "    # 3. GENERATE SUBMISSION (Traffic Light Logic)\n",
        "    # ==========================================\n",
        "    print(\"Step 3: Generating Self-Correcting Submission...\")\n",
        "\n",
        "    # Load Test Data (UPDATED FILENAME: test.csv)\n",
        "    if os.path.exists(\"test.csv\"):\n",
        "        df_test = pd.read_csv(\"test.csv\")\n",
        "        print(\"   üìÇ Loaded 'test.csv'\")\n",
        "    else:\n",
        "        print(\"‚ö†Ô∏è 'test.csv' not found. Generating mock test data...\")\n",
        "        df_test = df_raw.iloc[:2000].drop('is_fraud', axis=1).copy()\n",
        "\n",
        "    # Process\n",
        "    df_test_proc = engineer_features(df_test)\n",
        "    X_test_scaled = scaler.transform(df_test_proc[FEATURES])\n",
        "\n",
        "    # 1. Get Raw Scores\n",
        "    pred_ae = autoencoder.predict(X_test_scaled)\n",
        "    mse = np.mean(np.power(X_test_scaled - pred_ae, 2), axis=1) # Anomaly Score\n",
        "    prob_xgb = xgb_model.predict_proba(X_test_scaled)[:, 1]     # Pattern Score\n",
        "\n",
        "    # Hybrid Fusion (40% Anomaly + 60% Pattern)\n",
        "    raw_risk = (0.4 * mse) + (0.6 * prob_xgb)\n",
        "\n",
        "    # 2. QUANTILE NORMALIZATION (Traffic Light Logic)\n",
        "    # Force Operational Stability: Top 2% Block, Next 5% Review\n",
        "    cutoff_block = np.percentile(raw_risk, 98)\n",
        "    cutoff_review = np.percentile(raw_risk, 93)\n",
        "\n",
        "    def assign_action(score):\n",
        "        if score >= cutoff_block: return \"BLOCK\"\n",
        "        elif score >= cutoff_review: return \"REVIEW\"\n",
        "        else: return \"APPROVE\"\n",
        "\n",
        "    actions = [assign_action(s) for s in raw_risk]\n",
        "\n",
        "    # Output\n",
        "    submission = pd.DataFrame({\n",
        "        'transaction_id': df_test['transaction_id'],\n",
        "        'is_fraud': (raw_risk >= cutoff_review).astype(int), # 1 if Review or Block\n",
        "        'risk_score': np.round(raw_risk, 4),\n",
        "        'action': actions\n",
        "    })\n",
        "\n",
        "    submission.to_csv(\"submission_final.csv\", index=False)\n",
        "    print(\"üéâ SUCCESS: 'submission_final.csv' generated.\")\n",
        "    print(\"\\nüìä Final Operational Distribution:\")\n",
        "    print(submission['action'].value_counts())\n",
        "\n",
        "except Exception as e:\n",
        "    print(f\"‚ùå Error: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PQDnONiWITHn",
        "outputId": "5e9fffd9-be83-4e98-9a2c-c83cc07dcbe6"
      },
      "id": "PQDnONiWITHn",
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üöÄ Starting Hybrid AI Fraud Detection System...\n",
            "Step 1: Loading & Engineering Data...\n",
            "Step 2: Training Hybrid Engines...\n",
            "   ‚úÖ Autoencoder Trained (Anomaly Engine)\n",
            "   ‚úÖ XGBoost Trained with SMOTE (Pattern Engine)\n",
            "Step 3: Generating Self-Correcting Submission...\n",
            "   üìÇ Loaded 'test.csv'\n",
            "üéâ SUCCESS: 'submission_final.csv' generated.\n",
            "\n",
            "üìä Final Operational Distribution:\n",
            "action\n",
            "APPROVE    46\n",
            "REVIEW      3\n",
            "BLOCK       1\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}